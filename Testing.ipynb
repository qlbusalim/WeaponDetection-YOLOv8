{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install ultralytics"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fUKZWxYYsKPf","executionInfo":{"status":"ok","timestamp":1750144751989,"user_tz":-420,"elapsed":106612,"user":{"displayName":"Qolbu Salim qolbusalim.2023","userId":"15142425005989674719"}},"outputId":"994b0b96-f9a3-44ed-ea23-0d367b313511"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ultralytics\n","  Downloading ultralytics-8.3.155-py3-none-any.whl.metadata (37 kB)\n","Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n","Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.3)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n","Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n","  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.58.2)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.4.26)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.14.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n","Downloading ultralytics-8.3.155-py3-none-any.whl (1.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n","Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.155 ultralytics-thop-2.0.14\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1M7kTdtqLkLt","executionInfo":{"status":"ok","timestamp":1750144822340,"user_tz":-420,"elapsed":55719,"user":{"displayName":"Qolbu Salim qolbusalim.2023","userId":"15142425005989674719"}},"outputId":"e47d64be-97c8-461b-e593-83caf6348073"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["from ultralytics import YOLO\n","import cv2\n","import yaml\n","import os\n","import time\n","\n","# Load your trained model - update path to your best weights\n","model_path = \"/content/drive/MyDrive/Pengolahan Citra Digital/test_detect/best (1).pt\"\n","model = YOLO(model_path)\n","\n","# Load class names\n","with open(\"/content/drive/MyDrive/Pengolahan Citra Digital/combined_gunsnknifes/data.yaml\", 'r') as f:\n","    data = yaml.safe_load(f)\n","    class_names = data['names']\n","    print(\"Classes:\", class_names)\n","\n","# Input and output video paths\n","input_video_path = \"/content/drive/MyDrive/Pengolahan Citra Digital/test_detect/knife_testing4.mp4\"  # replace with your video path\n","output_video_path = \"/content/drive/MyDrive/Pengolahan Citra Digital/test_detect/knife_testing4_detect.mp4\"\n","\n","# Open the video\n","cap = cv2.VideoCapture(input_video_path)\n","if not cap.isOpened():\n","    print(\"Error: Could not open video.\")\n","    exit()\n","\n","# Get video properties\n","width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","fps = cap.get(cv2.CAP_PROP_FPS)\n","total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","\n","# Initialize video writer\n","fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n","out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n","\n","# Process video frame by frame\n","frame_count = 0\n","start_time = time.time()\n","\n","while cap.isOpened():\n","    success, frame = cap.read()\n","    if not success:\n","        break\n","\n","    # Increment frame counter\n","    frame_count += 1\n","\n","    if frame_count % 10 == 0:  # Update progress every 10 frames\n","        elapsed_time = time.time() - start_time\n","        frames_left = total_frames - frame_count\n","        time_left = frames_left * elapsed_time / frame_count if frame_count > 0 else 0\n","        print(f\"Processing frame {frame_count}/{total_frames} - ETA: {time_left:.1f}s\")\n","\n","    # Run detection on the frame\n","    results = model(frame, conf=0.30, iou=0.45)\n","\n","    # Visualize the results on the frame\n","    annotated_frame = results[0].plot()\n","\n","    # Write the frame to the output video\n","    out.write(annotated_frame)\n","\n","    # Uncomment to display the processing (will be slower)\n","    # cv2.imshow(\"Weapon Detection\", annotated_frame)\n","    # if cv2.waitKey(1) & 0xFF == ord('q'):\n","    #     break\n","\n","# Release resources\n","cap.release()\n","out.release()\n","cv2.destroyAllWindows()\n","\n","print(f\"Video processing complete! Output saved to {output_video_path}\")\n","print(f\"Total processing time: {time.time() - start_time:.2f} seconds\")"],"metadata":{"id":"rBHF8kCgghKG","executionInfo":{"status":"aborted","timestamp":1750144756211,"user_tz":-420,"elapsed":5,"user":{"displayName":"Qolbu Salim qolbusalim.2023","userId":"15142425005989674719"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Realtime Use**"],"metadata":{"id":"6KZWN7vdt7TG"}},{"cell_type":"code","source":["from ultralytics import YOLO\n","import cv2\n","import yaml\n","import numpy as np\n","import time\n","from IPython.display import display, Javascript, HTML\n","from google.colab.output import eval_js\n","from base64 import b64decode, b64encode\n","import PIL\n","import io\n","import html\n","import threading\n","import IPython\n","\n","# Global flag to control the detection loop\n","STOP_DETECTION = False\n","\n","# Load your trained model - update path to your best weights\n","model_path = \"/content/drive/MyDrive/Pengolahan Citra Digital/test_detect/best (1).pt\"\n","model = YOLO(model_path)\n","\n","# Load class names\n","with open(\"/content/drive/MyDrive/Pengolahan Citra Digital/combined_gunsnknifes/data.yaml\", 'r') as f:\n","    data = yaml.safe_load(f)\n","    class_names = data['names']\n","    print(\"Classes:\", class_names)\n","\n","# JavaScript to access webcam\n","js_code = \"\"\"\n","async function captureFrame() {\n","    // Check if webcam access is already initialized\n","    if (!window.hasOwnProperty('webcamCapture')) {\n","        // Create video element for webcam\n","        const video = document.createElement('video');\n","        video.style.display = 'none';\n","        document.body.appendChild(video);\n","\n","        // Create canvas for capturing frames\n","        const canvas = document.createElement('canvas');\n","        canvas.style.display = 'none';\n","        document.body.appendChild(canvas);\n","\n","        // Store elements globally\n","        window.webcamCapture = {\n","            video: video,\n","            canvas: canvas,\n","            initialized: false\n","        };\n","    }\n","\n","    const {video, canvas, initialized} = window.webcamCapture;\n","\n","    // Initialize webcam if not already done\n","    if (!initialized) {\n","        try {\n","            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n","            video.srcObject = stream;\n","            video.play();\n","            // Wait for video to be ready\n","            await new Promise(resolve => video.onloadedmetadata = resolve);\n","            canvas.width = video.videoWidth;\n","            canvas.height = video.videoHeight;\n","            window.webcamCapture.initialized = true;\n","        } catch (error) {\n","            console.error('Error accessing webcam:', error);\n","            return null;\n","        }\n","    }\n","\n","    // Capture current frame\n","    const ctx = canvas.getContext('2d');\n","    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);\n","    const dataUrl = canvas.toDataURL('image/jpeg');\n","\n","    return {\n","        dataUrl: dataUrl,\n","        width: canvas.width,\n","        height: canvas.height\n","    };\n","}\n","captureFrame();\n","\"\"\"\n","\n","# Function to stop the webcam stream\n","js_stop_webcam = \"\"\"\n","function stopWebcam() {\n","    if (window.hasOwnProperty('webcamCapture') && window.webcamCapture.video.srcObject) {\n","        const tracks = window.webcamCapture.video.srcObject.getTracks();\n","        tracks.forEach(track => track.stop());\n","        return true;\n","    }\n","    return false;\n","}\n","stopWebcam();\n","\"\"\"\n","\n","# Function to convert base64 to cv2 image\n","def js_to_image(js_reply):\n","    if not js_reply or not js_reply.get('dataUrl'):\n","        return None\n","\n","    # Extract the base64 data\n","    b64_data = js_reply['dataUrl'].split(',')[1]\n","    bytes_data = b64decode(b64_data)\n","\n","    # Convert to cv2 image (numpy array)\n","    img = PIL.Image.open(io.BytesIO(bytes_data))\n","    return cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n","\n","# Function to convert cv2 image to base64 for display\n","def image_to_b64(img):\n","    _, buffer = cv2.imencode('.jpg', img)\n","    jpg_as_text = b64encode(buffer).decode('utf-8')\n","    return f'data:image/jpeg;base64,{jpg_as_text}'\n","\n","# Function to perform real-time detection\n","def real_time_detection(conf_threshold=0.30, iou_threshold=0.45):\n","    global STOP_DETECTION\n","    STOP_DETECTION = False\n","    frame_count = 0\n","\n","    # Create display elements\n","    display_html = HTML(\"\"\"\n","    <div style=\"display: flex; justify-content: center;\">\n","        <img id=\"webcam-output\" style=\"width: 640px;\"/>\n","    </div>\n","    <div id=\"status\" style=\"text-align: center; font-weight: bold; margin-top: 10px;\">Initializing webcam...</div>\n","    <div style=\"text-align: center; margin-top: 10px;\">\n","        To stop detection, run the following in a new cell: <code>stop_detection()</code>\n","    </div>\n","    \"\"\")\n","    display(display_html)\n","\n","    print(\"Webcam detection started. Run stop_detection() in a new cell to stop.\")\n","\n","    while not STOP_DETECTION:\n","        try:\n","            # Capture frame from webcam\n","            js_reply = eval_js(js_code)\n","            if not js_reply:\n","                print(\"Failed to access webcam. Please check your browser permissions.\")\n","                break\n","\n","            # Convert to cv2 image\n","            frame = js_to_image(js_reply)\n","            if frame is None:\n","                continue\n","\n","            # Process frame with YOLO model\n","            start_time = time.time()\n","            results = model(frame, conf=conf_threshold, iou=iou_threshold)\n","            inference_time = time.time() - start_time\n","\n","            # Draw results on frame\n","            annotated_frame = results[0].plot()\n","\n","            # Add FPS information\n","            fps = 1.0 / inference_time\n","            frame_count += 1\n","            cv2.putText(annotated_frame, f\"FPS: {fps:.1f}\", (20, 40),\n","                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n","\n","            # Convert to base64 for display\n","            img_data = image_to_b64(annotated_frame)\n","\n","            # Update display\n","            eval_js(f\"\"\"\n","            document.getElementById('webcam-output').src = \"{img_data}\";\n","            document.getElementById('status').innerText = \"Frame {frame_count} - FPS: {fps:.1f}\";\n","            \"\"\")\n","\n","            # Short delay to allow for display update and reduce CPU usage\n","            time.sleep(0.01)\n","\n","        except Exception as e:\n","            print(f\"Error: {e}\")\n","            break\n","\n","    # Clean up webcam when done\n","    try:\n","        eval_js(js_stop_webcam)\n","    except:\n","        pass\n","\n","    print(\"Real-time detection stopped.\")\n","\n","# Function to stop detection from another cell\n","def stop_detection():\n","    global STOP_DETECTION\n","    STOP_DETECTION = True\n","    print(\"Stopping detection. Please wait...\")\n","\n","# Register the stop function so it can be called from other cells\n","IPython.get_ipython().user_ns[\"stop_detection\"] = stop_detection\n","\n","# Start the real-time detection\n","real_time_detection()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":958},"id":"8FlJ8TmUmCXF","executionInfo":{"status":"error","timestamp":1750145116664,"user_tz":-420,"elapsed":1554,"user":{"displayName":"Qolbu Salim qolbusalim.2023","userId":"15142425005989674719"}},"outputId":"b9d11e61-5192-4297-f2e1-310127906ec3"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Classes: ['pistol', 'knife']\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div style=\"display: flex; justify-content: center;\">\n","        <img id=\"webcam-output\" style=\"width: 640px;\"/>\n","    </div>\n","    <div id=\"status\" style=\"text-align: center; font-weight: bold; margin-top: 10px;\">Initializing webcam...</div>\n","    <div style=\"text-align: center; margin-top: 10px;\">\n","        To stop detection, run the following in a new cell: <code>stop_detection()</code>\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Webcam detection started. Run stop_detection() in a new cell to stop.\n","\n","0: 480x640 (no detections), 8.9ms\n","Speed: 1.7ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-2137443292>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;31m# Start the real-time detection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m \u001b[0mreal_time_detection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-8-2137443292>\u001b[0m in \u001b[0;36mreal_time_detection\u001b[0;34m(conf_threshold, iou_threshold)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0;31m# Capture frame from webcam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0mjs_reply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_js\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjs_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mjs_reply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Failed to access webcam. Please check your browser permissions.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["stop_detection()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RzpLDn_Vmedm","executionInfo":{"status":"ok","timestamp":1749001759674,"user_tz":-420,"elapsed":18,"user":{"displayName":"Qolbu Salim qolbusalim.2023","userId":"15142425005989674719"}},"outputId":"a9a705bc-0bdb-4367-d665-9e8a160f68df"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Stopping detection. Please wait...\n"]}]},{"cell_type":"code","source":["from ultralytics import YOLO\n","import cv2\n","import yaml\n","import numpy as np\n","import time\n","from IPython.display import display, Javascript, HTML\n","from google.colab.output import eval_js\n","from base64 import b64decode, b64encode\n","import PIL\n","import io\n","import threading\n","import IPython\n","\n","# Global flag to control the detection loop\n","STOP_DETECTION = False\n","\n","# Load your trained model - update path to your best weights\n","model_path = \"/content/drive/MyDrive/Pengolahan Citra Digital/test_detect/best (1).pt\"\n","model = YOLO(model_path)\n","\n","# Load class names\n","with open(\"/content/drive/MyDrive/Pengolahan Citra Digital/combined_gunsnknifes/data.yaml\", 'r') as f:\n","    data = yaml.safe_load(f)\n","    class_names = data['names']\n","    print(\"Classes:\", class_names)\n","\n","# JavaScript to access webcam\n","js_code = \"\"\"\n","async function captureFrame() {\n","    // Check if webcam access is already initialized\n","    if (!window.hasOwnProperty('webcamCapture')) {\n","        // Create video element for webcam\n","        const video = document.createElement('video');\n","        video.style.display = 'none';\n","        document.body.appendChild(video);\n","\n","        // Create canvas for capturing frames\n","        const canvas = document.createElement('canvas');\n","        canvas.style.display = 'none';\n","        document.body.appendChild(canvas);\n","\n","        // Store elements globally\n","        window.webcamCapture = {\n","            video: video,\n","            canvas: canvas,\n","            initialized: false\n","        };\n","    }\n","\n","    const {video, canvas, initialized} = window.webcamCapture;\n","\n","    // Initialize webcam if not already done\n","    if (!initialized) {\n","        try {\n","            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n","            video.srcObject = stream;\n","            video.play();\n","            // Wait for video to be ready\n","            await new Promise(resolve => video.onloadedmetadata = resolve);\n","            canvas.width = video.videoWidth;\n","            canvas.height = video.videoHeight;\n","            window.webcamCapture.initialized = true;\n","        } catch (error) {\n","            console.error('Error accessing webcam:', error);\n","            return null;\n","        }\n","    }\n","\n","    // Capture current frame\n","    const ctx = canvas.getContext('2d');\n","    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);\n","    const dataUrl = canvas.toDataURL('image/jpeg');\n","\n","    return {\n","        dataUrl: dataUrl,\n","        width: canvas.width,\n","        height: canvas.height\n","    };\n","}\n","captureFrame();\n","\"\"\"\n","\n","# Function to stop the webcam stream\n","js_stop_webcam = \"\"\"\n","function stopWebcam() {\n","    if (window.hasOwnProperty('webcamCapture') && window.webcamCapture.video.srcObject) {\n","        const tracks = window.webcamCapture.video.srcObject.getTracks();\n","        tracks.forEach(track => track.stop());\n","        return true;\n","    }\n","    return false;\n","}\n","stopWebcam();\n","\"\"\"\n","\n","# Function to convert base64 to cv2 image\n","def js_to_image(js_reply):\n","    if not js_reply or not js_reply.get('dataUrl'):\n","        return None\n","\n","    # Extract the base64 data\n","    b64_data = js_reply['dataUrl'].split(',')[1]\n","    bytes_data = b64decode(b64_data)\n","\n","    # Convert to cv2 image (numpy array)\n","    img = PIL.Image.open(io.BytesIO(bytes_data))\n","    return cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n","\n","# Function to convert cv2 image to base64 for display\n","def image_to_b64(img):\n","    _, buffer = cv2.imencode('.jpg', img)\n","    jpg_as_text = b64encode(buffer).decode('utf-8')\n","    return f'data:image/jpeg;base64,{jpg_as_text}'\n","\n","# Simple tracker class for object tracking\n","class SimpleTracker:\n","    def __init__(self, max_disappeared=30, max_distance=50):\n","        self.nextObjectID = 0\n","        self.objects = {}  # Dictionary of centroids with format {ID: (x, y)}\n","        self.disappeared = {}  # Dictionary to count frames an object has been missing\n","        self.max_disappeared = max_disappeared\n","        self.max_distance = max_distance\n","        self.object_data = {}  # Store additional data about objects\n","\n","    def register(self, centroid, bbox, class_id):\n","        # Register a new object\n","        self.objects[self.nextObjectID] = centroid\n","        self.disappeared[self.nextObjectID] = 0\n","        self.object_data[self.nextObjectID] = {\n","            'bbox': bbox,\n","            'class_id': class_id,\n","            'history': [centroid]\n","        }\n","        self.nextObjectID += 1\n","\n","    def deregister(self, objectID):\n","        # Deregister an object\n","        del self.objects[objectID]\n","        del self.disappeared[objectID]\n","        del self.object_data[objectID]\n","\n","    def update(self, detections):\n","        # detections: list of [bbox, class_id, confidence]\n","        # Returns dictionary of tracked objects\n","\n","        # If no detections, mark all existing objects as disappeared\n","        if len(detections) == 0:\n","            for objectID in list(self.disappeared.keys()):\n","                self.disappeared[objectID] += 1\n","\n","                # Deregister if object has been missing for too long\n","                if self.disappeared[objectID] > self.max_disappeared:\n","                    self.deregister(objectID)\n","\n","            return self.object_data\n","\n","        # If we're currently not tracking any objects, register all detections\n","        if len(self.objects) == 0:\n","            for detection in detections:\n","                bbox, class_id, confidence = detection\n","                x1, y1, x2, y2 = bbox\n","                centroid = ((x1 + x2) // 2, (y1 + y2) // 2)\n","                self.register(centroid, bbox, class_id)\n","        else:\n","            # Get centroids of current detections\n","            new_centroids = []\n","            for detection in detections:\n","                bbox, class_id, confidence = detection\n","                x1, y1, x2, y2 = bbox\n","                centroid = ((x1 + x2) // 2, (y1 + y2) // 2)\n","                new_centroids.append((centroid, bbox, class_id, confidence))\n","\n","            # Match existing objects to new detections\n","            object_ids = list(self.objects.keys())\n","            object_centroids = list(self.objects.values())\n","\n","            # Calculate distances between each pair of existing and new centroids\n","            distances = {}\n","            for i, objectID in enumerate(object_ids):\n","                distances[objectID] = {}\n","                for j, (centroid, bbox, class_id, confidence) in enumerate(new_centroids):\n","                    # Use Euclidean distance\n","                    d = np.sqrt((object_centroids[i][0] - centroid[0])**2 +\n","                               (object_centroids[i][1] - centroid[1])**2)\n","                    distances[objectID][j] = d\n","\n","            # Find the smallest distance for each object and update if it's below threshold\n","            used_detections = set()\n","            for objectID in object_ids:\n","                if not distances[objectID]:  # Skip if no distances for this object\n","                    continue\n","\n","                # Find closest detection\n","                min_dist_idx = min(distances[objectID], key=distances[objectID].get)\n","                min_dist = distances[objectID][min_dist_idx]\n","\n","                # Only update if distance is below threshold\n","                if min_dist <= self.max_distance and min_dist_idx not in used_detections:\n","                    centroid, bbox, class_id, confidence = new_centroids[min_dist_idx]\n","                    self.objects[objectID] = centroid\n","                    self.disappeared[objectID] = 0\n","                    self.object_data[objectID]['bbox'] = bbox\n","                    self.object_data[objectID]['class_id'] = class_id\n","                    self.object_data[objectID]['confidence'] = confidence\n","                    self.object_data[objectID]['history'].append(centroid)\n","                    # Keep history at a reasonable length\n","                    if len(self.object_data[objectID]['history']) > 30:\n","                        self.object_data[objectID]['history'] = self.object_data[objectID]['history'][-30:]\n","                    used_detections.add(min_dist_idx)\n","                else:\n","                    # Mark as disappeared if no matching detection found\n","                    self.disappeared[objectID] += 1\n","\n","            # Check for disappeared objects\n","            for objectID in list(self.disappeared.keys()):\n","                if self.disappeared[objectID] > self.max_disappeared:\n","                    self.deregister(objectID)\n","\n","            # Register new detections that weren't matched\n","            for i, (centroid, bbox, class_id, confidence) in enumerate(new_centroids):\n","                if i not in used_detections:\n","                    self.register(centroid, bbox, class_id)\n","\n","        return self.object_data\n","\n","# Initialize tracker\n","tracker = SimpleTracker(max_disappeared=10, max_distance=100)\n","\n","# Function to perform real-time detection with tracking\n","def real_time_detection_with_tracking(conf_threshold=0.30, iou_threshold=0.45):\n","    global STOP_DETECTION\n","    STOP_DETECTION = False\n","    frame_count = 0\n","\n","    # Track colors for visualization\n","    def get_color(track_id):\n","        # Generate a color based on track ID (consistent across frames)\n","        np.random.seed(track_id * 123)\n","        return (int(np.random.randint(0, 255)),\n","                int(np.random.randint(0, 255)),\n","                int(np.random.randint(0, 255)))\n","\n","    # Create display elements\n","    display_html = HTML(\"\"\"\n","    <div style=\"display: flex; justify-content: center;\">\n","        <img id=\"webcam-output\" style=\"width: 640px;\"/>\n","    </div>\n","    <div id=\"status\" style=\"text-align: center; font-weight: bold; margin-top: 10px;\">Initializing webcam...</div>\n","    <div style=\"text-align: center; margin-top: 10px;\">\n","        To stop detection, run the following in a new cell: <code>stop_detection()</code>\n","    </div>\n","    \"\"\")\n","    display(display_html)\n","\n","    print(\"Webcam detection with tracking started. Run stop_detection() in a new cell to stop.\")\n","\n","    while not STOP_DETECTION:\n","        try:\n","            # Capture frame from webcam\n","            js_reply = eval_js(js_code)\n","            if not js_reply:\n","                print(\"Failed to access webcam. Please check your browser permissions.\")\n","                break\n","\n","            # Convert to cv2 image\n","            frame = js_to_image(js_reply)\n","            if frame is None:\n","                continue\n","\n","            # Process frame with YOLO model\n","            start_time = time.time()\n","            results = model(frame, conf=conf_threshold, iou=iou_threshold)\n","            inference_time = time.time() - start_time\n","\n","            # Prepare detections for tracker\n","            detections = []\n","            for box in results[0].boxes:\n","                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)\n","                confidence = float(box.conf[0].cpu().numpy())\n","                class_id = int(box.cls[0].cpu().numpy())\n","                detections.append([(x1, y1, x2, y2), class_id, confidence])\n","\n","            # Update tracker\n","            tracked_objects = tracker.update(detections)\n","\n","            # Create a copy of the frame for visualization\n","            tracked_frame = frame.copy()\n","\n","            # Visualize the tracked objects\n","            for track_id, data in tracked_objects.items():\n","                bbox = data['bbox']\n","                class_id = data['class_id']\n","                history = data['history']\n","\n","                # Get color based on track ID\n","                color = get_color(track_id)\n","\n","                # Draw bounding box\n","                cv2.rectangle(tracked_frame, (bbox[0], bbox[1]), (bbox[2], bbox[3]), color, 2)\n","\n","                # Add label with track ID and class\n","                class_name = class_names[class_id]\n","                label = f\"{class_name}-{track_id}\"\n","                cv2.putText(tracked_frame, label, (bbox[0], bbox[1] - 10),\n","                            cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n","\n","                # Draw tracking lines (history)\n","                if len(history) > 1:\n","                    for i in range(1, len(history)):\n","                        pt1 = history[i-1]\n","                        pt2 = history[i]\n","                        cv2.line(tracked_frame, pt1, pt2, color, 2)\n","\n","            # Add FPS information\n","            fps = 1.0 / inference_time\n","            frame_count += 1\n","            cv2.putText(tracked_frame, f\"FPS: {fps:.1f}\", (20, 40),\n","                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n","\n","            # Convert to base64 for display\n","            img_data = image_to_b64(tracked_frame)\n","\n","            # Update display\n","            eval_js(f\"\"\"\n","            document.getElementById('webcam-output').src = \"{img_data}\";\n","            document.getElementById('status').innerText = \"Frame {frame_count} - FPS: {fps:.1f} - Tracking {len(tracked_objects)} objects\";\n","            \"\"\")\n","\n","            # Short delay to allow for display update\n","            time.sleep(0.01)\n","\n","        except Exception as e:\n","            print(f\"Error: {e}\")\n","            import traceback\n","            traceback.print_exc()\n","            break\n","\n","    # Clean up webcam when done\n","    try:\n","        eval_js(js_stop_webcam)\n","    except:\n","        pass\n","\n","    print(\"Real-time detection with tracking stopped.\")\n","\n","# Function to stop detection from another cell\n","def stop_detection():\n","    global STOP_DETECTION\n","    STOP_DETECTION = True\n","    print(\"Stopping detection. Please wait...\")\n","\n","# Register the stop function so it can be called from other cells\n","IPython.get_ipython().user_ns[\"stop_detection\"] = stop_detection\n","\n","# Start the real-time detection with tracking\n","real_time_detection_with_tracking()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"JrZuyWQHpk3m","outputId":"5ef2d726-2c7b-4ae3-bce4-d8a731d4f4b1","executionInfo":{"status":"error","timestamp":1750144978199,"user_tz":-420,"elapsed":96475,"user":{"displayName":"Qolbu Salim qolbusalim.2023","userId":"15142425005989674719"}}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Classes: ['pistol', 'knife']\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div style=\"display: flex; justify-content: center;\">\n","        <img id=\"webcam-output\" style=\"width: 640px;\"/>\n","    </div>\n","    <div id=\"status\" style=\"text-align: center; font-weight: bold; margin-top: 10px;\">Initializing webcam...</div>\n","    <div style=\"text-align: center; margin-top: 10px;\">\n","        To stop detection, run the following in a new cell: <code>stop_detection()</code>\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Webcam detection with tracking started. Run stop_detection() in a new cell to stop.\n","\n","0: 480x640 (no detections), 40.0ms\n","Speed: 9.9ms preprocess, 40.0ms inference, 104.7ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 9.4ms\n","Speed: 4.5ms preprocess, 9.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 14.8ms\n","Speed: 2.0ms preprocess, 14.8ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 9.0ms\n","Speed: 2.1ms preprocess, 9.0ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 7.4ms\n","Speed: 2.0ms preprocess, 7.4ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 9.1ms\n","Speed: 1.9ms preprocess, 9.1ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 9.8ms\n","Speed: 1.9ms preprocess, 9.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 7.3ms\n","Speed: 2.1ms preprocess, 7.3ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 7.1ms\n","Speed: 2.1ms preprocess, 7.1ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 8.6ms\n","Speed: 2.0ms preprocess, 8.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 knife, 8.9ms\n","Speed: 2.3ms preprocess, 8.9ms inference, 248.0ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 7.7ms\n","Speed: 2.3ms preprocess, 7.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 10.6ms\n","Speed: 2.2ms preprocess, 10.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 7.1ms\n","Speed: 2.2ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 knife, 7.9ms\n","Speed: 1.9ms preprocess, 7.9ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 knife, 12.5ms\n","Speed: 3.0ms preprocess, 12.5ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 knife, 11.6ms\n","Speed: 2.6ms preprocess, 11.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 knife, 9.7ms\n","Speed: 1.9ms preprocess, 9.7ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 knife, 16.4ms\n","Speed: 3.5ms preprocess, 16.4ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 7.6ms\n","Speed: 2.0ms preprocess, 7.6ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 pistol, 7.5ms\n","Speed: 2.1ms preprocess, 7.5ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 pistol, 7.7ms\n","Speed: 2.3ms preprocess, 7.7ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 pistol, 8.9ms\n","Speed: 1.8ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 pistol, 7.5ms\n","Speed: 2.3ms preprocess, 7.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 7.6ms\n","Speed: 2.2ms preprocess, 7.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 pistol, 6.9ms\n","Speed: 1.9ms preprocess, 6.9ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 pistol, 8.4ms\n","Speed: 2.2ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 pistol, 8.3ms\n","Speed: 2.4ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 7.3ms\n","Speed: 2.0ms preprocess, 7.3ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 pistol, 7.6ms\n","Speed: 1.9ms preprocess, 7.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 pistol, 9.5ms\n","Speed: 2.2ms preprocess, 9.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 pistol, 13.4ms\n","Speed: 2.0ms preprocess, 13.4ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 pistol, 7.3ms\n","Speed: 2.3ms preprocess, 7.3ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 pistol, 7.3ms\n","Speed: 2.1ms preprocess, 7.3ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 pistol, 7.4ms\n","Speed: 2.2ms preprocess, 7.4ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 13.6ms\n","Speed: 3.0ms preprocess, 13.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 pistol, 11.8ms\n","Speed: 2.0ms preprocess, 11.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 12.1ms\n","Speed: 2.0ms preprocess, 12.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 12.9ms\n","Speed: 1.9ms preprocess, 12.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 8.6ms\n","Speed: 2.1ms preprocess, 8.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 7.3ms\n","Speed: 2.1ms preprocess, 7.3ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 7.2ms\n","Speed: 2.0ms preprocess, 7.2ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 8.2ms\n","Speed: 2.3ms preprocess, 8.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 7.1ms\n","Speed: 1.9ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 13.1ms\n","Speed: 2.1ms preprocess, 13.1ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 7.3ms\n","Speed: 2.2ms preprocess, 7.3ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 pistol, 7.1ms\n","Speed: 2.2ms preprocess, 7.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 pistol, 7.3ms\n","Speed: 2.0ms preprocess, 7.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 pistol, 8.0ms\n","Speed: 2.1ms preprocess, 8.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 7.7ms\n","Speed: 1.8ms preprocess, 7.7ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 9.2ms\n","Speed: 2.0ms preprocess, 9.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 7.2ms\n","Speed: 2.3ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 7.0ms\n","Speed: 2.0ms preprocess, 7.0ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 pistol, 7.6ms\n","Speed: 2.0ms preprocess, 7.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 10.6ms\n","Speed: 2.2ms preprocess, 10.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 pistol, 9.8ms\n","Speed: 1.8ms preprocess, 9.8ms inference, 5.5ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 knife, 10.7ms\n","Speed: 2.0ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 knife, 10.1ms\n","Speed: 2.0ms preprocess, 10.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 7.1ms\n","Speed: 1.8ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 7.5ms\n","Speed: 2.3ms preprocess, 7.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 9.8ms\n","Speed: 2.4ms preprocess, 9.8ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 8.2ms\n","Speed: 2.0ms preprocess, 8.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 7.1ms\n","Speed: 2.3ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 7.5ms\n","Speed: 2.1ms preprocess, 7.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 7.4ms\n","Speed: 2.1ms preprocess, 7.4ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 7.9ms\n","Speed: 2.1ms preprocess, 7.9ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 8.0ms\n","Speed: 2.1ms preprocess, 8.0ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 7.6ms\n","Speed: 2.2ms preprocess, 7.6ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 pistol, 11.8ms\n","Speed: 2.0ms preprocess, 11.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 pistol, 12.8ms\n","Speed: 2.0ms preprocess, 12.8ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 pistol, 13.4ms\n","Speed: 3.1ms preprocess, 13.4ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 pistol, 9.9ms\n","Speed: 2.1ms preprocess, 9.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 pistol, 10.0ms\n","Speed: 2.3ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 7.1ms\n","Speed: 2.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 7.4ms\n","Speed: 1.8ms preprocess, 7.4ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 10.9ms\n","Speed: 3.8ms preprocess, 10.9ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 7.4ms\n","Speed: 1.9ms preprocess, 7.4ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 11.9ms\n","Speed: 1.8ms preprocess, 11.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 7.2ms\n","Speed: 1.8ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 12.5ms\n","Speed: 2.1ms preprocess, 12.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 9.4ms\n","Speed: 2.1ms preprocess, 9.4ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 9.8ms\n","Speed: 2.0ms preprocess, 9.8ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 7.7ms\n","Speed: 2.2ms preprocess, 7.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 7.4ms\n","Speed: 2.2ms preprocess, 7.4ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 7.5ms\n","Speed: 2.1ms preprocess, 7.5ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 7.7ms\n","Speed: 2.1ms preprocess, 7.7ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 11.5ms\n","Speed: 2.3ms preprocess, 11.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 7.5ms\n","Speed: 2.4ms preprocess, 7.5ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 7.5ms\n","Speed: 2.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 7.6ms\n","Speed: 2.1ms preprocess, 7.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 7.7ms\n","Speed: 2.2ms preprocess, 7.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 10.6ms\n","Speed: 2.4ms preprocess, 10.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 pistol, 8.8ms\n","Speed: 2.3ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 pistol, 7.5ms\n","Speed: 2.2ms preprocess, 7.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 pistol, 9.8ms\n","Speed: 1.9ms preprocess, 9.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 pistol, 9.0ms\n","Speed: 1.9ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 pistol, 10.7ms\n","Speed: 2.1ms preprocess, 10.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 pistol, 12.7ms\n","Speed: 1.9ms preprocess, 12.7ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 pistol, 13.9ms\n","Speed: 2.0ms preprocess, 13.9ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 pistol, 1 knife, 10.5ms\n","Speed: 2.1ms preprocess, 10.5ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 pistol, 1 knife, 7.6ms\n","Speed: 2.0ms preprocess, 7.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 pistol, 1 knife, 8.7ms\n","Speed: 2.2ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 pistol, 1 knife, 7.8ms\n","Speed: 2.4ms preprocess, 7.8ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 8.5ms\n","Speed: 2.0ms preprocess, 8.5ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 pistol, 1 knife, 8.1ms\n","Speed: 2.0ms preprocess, 8.1ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 pistol, 1 knife, 7.9ms\n","Speed: 2.3ms preprocess, 7.9ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 pistol, 1 knife, 10.0ms\n","Speed: 3.8ms preprocess, 10.0ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 13.0ms\n","Speed: 2.1ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 (no detections), 7.7ms\n","Speed: 1.8ms preprocess, 7.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-501566232>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0;31m# Start the real-time detection with tracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m \u001b[0mreal_time_detection_with_tracking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-6-501566232>\u001b[0m in \u001b[0;36mreal_time_detection_with_tracking\u001b[0;34m(conf_threshold, iou_threshold)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0;31m# Convert to cv2 image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m             \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjs_to_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjs_reply\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-501566232>\u001b[0m in \u001b[0;36mjs_to_image\u001b[0;34m(js_reply)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;31m# Convert to cv2 image (numpy array)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_RGB2BGR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;31m# Function to convert cv2 image to base64 for display\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["stop_detection"],"metadata":{"id":"Ig_RdU7uqSeV","executionInfo":{"status":"ok","timestamp":1749002313794,"user_tz":-420,"elapsed":82,"user":{"displayName":"Qolbu Salim qolbusalim.2023","userId":"15142425005989674719"}},"outputId":"fb645a8f-33fc-494d-deed-362cbdfaa454","colab":{"base_uri":"https://localhost:8080/","height":103}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<function __main__.stop_detection()>"],"text/html":["<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n","      pre.function-repr-contents {\n","        overflow-x: auto;\n","        padding: 8px 12px;\n","        max-height: 500px;\n","      }\n","\n","      pre.function-repr-contents.function-repr-contents-collapsed {\n","        cursor: pointer;\n","        max-height: 100px;\n","      }\n","    </style>\n","    <pre style=\"white-space: initial; background:\n","         var(--colab-secondary-surface-color); padding: 8px 12px;\n","         border-bottom: 1px solid var(--colab-border-color);\"><b>stop_detection</b><br/>def stop_detection()</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/content/&lt;ipython-input-12-a417223b1975&gt;</a>&lt;no docstring&gt;</pre></div>"]},"metadata":{},"execution_count":13}]}]}